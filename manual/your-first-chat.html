<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Your First Chat - @motioneffector/llm</title>
  <link rel="stylesheet" href="../demo-files/demo.css">
  <link rel="stylesheet" href="manual.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>document.addEventListener('DOMContentLoaded', () => hljs.highlightAll());</script>
</head>
<body>
  <div class="page">
    <header class="header">
      <h1 class="header-title">@motioneffector/llm</h1>
      <p class="header-description">Documentation</p>
      <nav class="header-links">
        <a href="../index.html" class="header-link">Demo</a>
        <a href="https://www.npmjs.com/package/@motioneffector/llm" class="header-link">npm</a>
        <a href="https://github.com/motioneffector/llm" class="header-link">GitHub</a>
      </nav>
    </header>

    <div class="manual-layout">
      <aside class="manual-sidebar">
        <nav class="sidebar-nav">
<p><strong><a href="index.html">@motioneffector/llm</a></strong></p>
<p><strong>Getting Started</strong></p>
<ul>
<li><a href="installation.html">Installation</a></li>
<li><a href="your-first-chat.html">Your First Chat</a></li>
</ul>
<p><strong>Core Concepts</strong></p>
<ul>
<li><a href="concept-client.html">Client</a></li>
<li><a href="concept-messages.html">Messages</a></li>
<li><a href="concept-streaming.html">Streaming</a></li>
<li><a href="concept-conversations.html">Conversations</a></li>
<li><a href="concept-error-handling.html">Error Handling</a></li>
</ul>
<p><strong>Guides</strong></p>
<ul>
<li><a href="guide-sending-messages.html">Sending Messages</a></li>
<li><a href="guide-streaming-responses.html">Streaming Responses</a></li>
<li><a href="guide-building-conversations.html">Building Conversations</a></li>
<li><a href="guide-error-handling.html">Error Handling</a></li>
<li><a href="guide-canceling-requests.html">Canceling Requests</a></li>
<li><a href="guide-using-different-providers.html">Using Different Providers</a></li>
</ul>
<p><strong>API Reference</strong></p>
<ul>
<li><a href="api-client.html">Client API</a></li>
<li><a href="api-conversation.html">Conversation API</a></li>
<li><a href="api-types.html">Types</a></li>
<li><a href="api-errors.html">Errors</a></li>
<li><a href="api-utilities.html">Utilities</a></li>
</ul>

        </nav>
      </aside>

      <main class="manual-content">
        <article class="manual-article">
<h1>Your First Chat</h1>
<p>Send a message to an LLM and get a response in under 5 minutes.</p>
<p>By the end of this guide, you&#39;ll have a working script that sends a message to Claude and prints the response with usage statistics.</p>
<h2>What We&#39;re Building</h2>
<p>A simple script that asks Claude to explain a concept and displays the response along with token usage and latency metrics:</p>
<pre><code>Quantum computing uses quantum bits (qubits) that can exist in multiple
states simultaneously, unlike classical bits...

Used 127 tokens in 1243ms
</code></pre>
<h2>Step 1: Get an API Key</h2>
<p>Sign up at <a href="https://openrouter.ai/">OpenRouter</a> and create an API key. OpenRouter provides access to 200+ models through a single API.</p>
<p>Set the key as an environment variable:</p>
<pre><code class="language-bash">export OPENROUTER_KEY=&quot;sk-or-v1-...&quot;
</code></pre>
<h2>Step 2: Create the Client</h2>
<p>The client is your connection to the API. Create it with your key and the model you want to use.</p>
<pre><code class="language-typescript">import { createLLMClient } from &#39;@motioneffector/llm&#39;

const client = createLLMClient({
  apiKey: process.env.OPENROUTER_KEY!,
  model: &#39;anthropic/claude-sonnet-4&#39;
})
</code></pre>
<p>The client handles authentication, retries, and request formatting automatically.</p>
<h2>Step 3: Send a Message</h2>
<p>Call <code>chat()</code> with an array of messages. Each message has a <code>role</code> and <code>content</code>.</p>
<pre><code class="language-typescript">const response = await client.chat([
  { role: &#39;user&#39;, content: &#39;Explain quantum computing in simple terms&#39; }
])
</code></pre>
<p>The library sends the request, waits for the response, and returns a structured result.</p>
<h2>Step 4: Use the Response</h2>
<p>The response object contains the generated text plus metadata about the request.</p>
<pre><code class="language-typescript">console.log(response.content)
console.log(`Used ${response.usage.totalTokens} tokens in ${response.latency}ms`)
</code></pre>
<h2>The Complete Code</h2>
<p>Here&#39;s everything together:</p>
<pre><code class="language-typescript">import { createLLMClient } from &#39;@motioneffector/llm&#39;

const client = createLLMClient({
  apiKey: process.env.OPENROUTER_KEY!,
  model: &#39;anthropic/claude-sonnet-4&#39;
})

const response = await client.chat([
  { role: &#39;user&#39;, content: &#39;Explain quantum computing in simple terms&#39; }
])

console.log(response.content)
console.log(`Used ${response.usage.totalTokens} tokens in ${response.latency}ms`)
</code></pre>
<p>Run it with:</p>
<pre><code class="language-bash">npx tsx chat.ts
</code></pre>
<h2>What&#39;s Next?</h2>
<p>Now that you have the basics:</p>
<ul>
<li><strong><a href="concept-client.html">Understand the Client</a></strong> - Learn how the client works and what you can configure</li>
<li><strong><a href="guide-streaming-responses.html">Stream Responses</a></strong> - Display text as it&#39;s generated instead of waiting</li>
<li><strong><a href="guide-building-conversations.html">Build Conversations</a></strong> - Create multi-turn dialogues with automatic history</li>
<li><strong><a href="api-client.html">Explore the API</a></strong> - Full reference when you need details</li>
</ul>

        </article>
      </main>
    </div>
  </div>
</body>
</html>
